# -*- coding: utf-8 -*-
"""British Airways Virtual Experience.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oyjxs1389lzdBI-xPq_s0hf1iGIXZr7W
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import requests
from bs4 import BeautifulSoup

# Commented out IPython magic to ensure Python compatibility.
import requests
import nltk
from bs4 import BeautifulSoup
import numpy as np 
import pandas as pd 
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
import random
from wordcloud import WordCloud
import os
import spacy
nlp = spacy.load('en_core_web_sm')
from textblob import TextBlob
! pip install pattern
from pattern.text import sentiment

# fetching the pages

result= requests.get('https://www.airlinequality.com/airline-reviews/british-airways/?sortby=post_date%3ADesc&pagesize=50')
print(result.status_code)
result.headers

# page content

content= result.text
content

# Creating Soup
soup = BeautifulSoup(content, 'html.parser')

# HTML in a readable format

print(soup.prettify())

for link in soup.find_all('a'):
    print(link.get('href'))

for ele in soup.find_all('a'):
    print(ele.get('href'))

for tag in soup.find_all('div'):
    print(tag.get_text()) # works

for tag in soup.find_all('p'):
    print(tag.get_text())

soup.find_all('a')
soup.get_text()

list_all = soup.find_all("div", class_="text_content ")
type(list_all)

for item in list_all:
    print(item.text)

#soup_text = soup.text
#soup_text
for i in list_all:
    print(i)

text_review=[]
for items in list_all:
    text_review.append(items.text)

for i in text_review:
    print(i)

text_review

for i in text_review:
    print(i)

textblob_sentiment=[]
for s in text_review:
    txt= TextBlob(s)
    a= txt.sentiment.polarity
    b= txt.sentiment.subjectivity
    textblob_sentiment.append([s,a,b])

df_textblob = pd.DataFrame(textblob_sentiment, columns =['Sentence', 'Polarity', 'Subjectivity'])

(df_textblob['Polarity'] > 0).value_counts() # positive and negative sentiment count
(df_textblob['Subjectivity'] > 0.5).value_counts()

sns.displot(df_textblob["Polarity"], height= 6, aspect=0.9)
plt.xlabel("Sentence Polarity (Textblob)")

sns.displot(df_textblob["Subjectivity"], height= 6, aspect=0.9)
plt.xlabel("Sentence Subjectivity (Textblob)")

plt.scatter(df_textblob["Polarity"],df_textblob["Subjectivity"])
plt.xlabel('Polarity (TextBlob)')
plt.ylabel('Subjectivity (TextBlob)')

df_textblob['Polarity'].median()
(df_textblob['Subjectivity'] > 0.50).value_counts()
df_textblob

import nltk
nltk.download('omw-1.4')
# sentiment analysis using pattern analysis
pattern_sentiment=[]
for s in text_review:
    res= sentiment(s)
    c= res[0]
    d= res[1]
    pattern_sentiment.append([s,c,d])

pattern_sentiment[1]

df_pattern = pd.DataFrame(textblob_sentiment, columns =['Sentence', 'Polarity', 'Subjectivity'])

df_pattern

print((df_pattern['Polarity']>0).value_counts())
(df_pattern['Subjectivity']>0.5).value_counts()
#print((df_pattern['Polarity']>0 df_pattern['Subjectivity']>0.5).value_counts())

sns.displot(df_pattern["Polarity"], height= 6, aspect=0.9)
plt.xlabel("Sentence Polarity (Pattern)")

sns.displot(df_pattern["Subjectivity"], height= 6, aspect=0.9)
plt.xlabel("Sentence Subjectivity (Pattern)")

plt.scatter(df_pattern['Polarity'],df_pattern['Subjectivity'])
plt.xlabel('Polarity (Pattern)')
plt.ylabel('Subjectivity (Pattern)')

df_pattern['Polarity'].median()
df_pattern['Subjectivity'].median()

#Creating the tokenizer
tokenizer = nltk.tokenize.RegexpTokenizer('w+')

words = []
words_new=[]
words_f=[]
'''
for i in text_review:
      (i.lower())
      print(i.split())
      words.append(i.split()) 


for i in words:
    for j in i:
        j.replace('(','')
        j.replace('|','')
        j.replace('✅','')
        words_new.append(j)  
'''
for i in text_review:
    words.append(i.lower())
words

for i in words:
        words_new.append(i.split())

words_new

for i in words_new:
    for j in i:
        words_f.append(j)

words_f

words_f

#Now we have to remove stopwords
#Stop words are a set of commonly used words in any language. 
#For example, in English, “the”, “is” and “and”, would easily qualify as stop words. 
#In NLP and text mining applications, stop words are used to eliminate unimportant words, 
#allowing applications to focus on the important words instead.
#English stop words from nltk
import nltk
nltk.download('stopwords')
stopwords = nltk.corpus.stopwords.words('english')

stopwords

len(words_f)

#Appending to words_new all words that are in words but not in sw
#for word in words_new:
 #   if word not in stopwords:
 #       words_new.append(word)

words_final=[]

for i in words_f:
    if i not in stopwords:
       words_final.append(i) 
words_final

#The frequency distribution of the words
freq_dist = nltk.FreqDist(words_final)
freq_dist

#Frequency Distribution Plot
plt.subplots(figsize=(9,15))
freq_dist.plot(20)

#converting into string
res=' '.join([i for i in words_final if not i.isdigit()])

plt.subplots(figsize=(15,9))
wordcloud = WordCloud(
                          background_color='Black',
                          max_words=100,
                          width=1400,
                          height=1200
                         ).generate(res)
plt.imshow(wordcloud)
plt.title('British Airways Reviews WordCloud (100 words)')
plt.axis('off')
plt.show()

"""# **Task 2**"""

#customer_data= pd.read_csv('/content/sample_data/customer_booking.csv',encoding_errors='ignore') # works, use whenever encoding related error occurs 
customer_data=pd.read_csv('https://cdn.theforage.com/vinternships/companyassets/tMjbs76F526fF5v3G/L3MQ8f6cYSkfoukmz/1667814300249/customer_booking.csv',encoding_errors='ignore')

print(customer_data['sales_channel'].value_counts())
print(customer_data['trip_type'].value_counts())
print(customer_data['flight_day'].value_counts())
print(customer_data['route'].value_counts())
print(customer_data['booking_origin'].value_counts())
print(customer_data['wants_preferred_seat'].value_counts())
print(customer_data['purchase_lead'].value_counts())
print(customer_data['booking_complete'].value_counts())
customer_data.info()

def colval_descriptor(dataset):
  ''' This function takes any dataset in the csv format as the input argument
      and returns a dictionary, with keys as the name of the columns and values 
      as the unique values present in the columns
  '''
  list1=[] # column names
  list2=[] # unique column values
  unique_descriptor = dict()
  for i in dataset.columns:
        list1.append(i)
        list2.append(dataset[i].unique())
        unique_descriptor= dict(zip(list1,list2))
        
  return  unique_descriptor

colval_descriptor(customer_data)

#customer_data_new=pd.get_dummies(customer_data, columns=['sales_channel','trip_type','flight_day','route', 'booking_origin','wants_extra_baggage','wants_preferred_seat','wants_in_flight_meals'] )

customer_data_new=pd.get_dummies(customer_data, columns=['sales_channel','trip_type','flight_day','route', 'booking_origin'] )
customer_data_new

customer_data_f= pd.get_dummies(customer_data)
customer_data_f

customer_data_f_corr= customer_data_f.corr()

customer_data_f_corr['booking_complete'].sort_values(ascending=False)[:40]

customer_data_corr= customer_data.corr()
customer_data_corr['booking_complete'].sort_values(ascending=False)

customer_data_s=pd.get_dummies(customer_data, columns=['booking_complete','sales_channel','trip_type','flight_day','route', 'booking_origin','wants_extra_baggage','wants_preferred_seat','wants_in_flight_meals'])

customer_data_s

customer_data_s_corr= customer_data_s.corr()

customer_data_s_corr['booking_complete_1'].sort_values(ascending=False)[:40]

(customer_data_s_corr['booking_complete_1'].sort_values(ascending=False)[:20]).plot(kind='barh')

customer_data.describe()
customer_data.median()

customer_data_m=pd.get_dummies(customer_data, columns=['sales_channel','trip_type','flight_day','route', 'booking_origin','wants_extra_baggage','wants_preferred_seat','wants_in_flight_meals'])

# Preparing dataset for training

# Training Data
X = customer_data_m.drop(labels='booking_complete', axis=1)


# Target
y = customer_data_m['booking_complete']

# Splitting the data into training dataset and test dataset 
from sklearn.model_selection import train_test_split 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42, shuffle=True)

from sklearn.ensemble import BaggingClassifier
from sklearn.neighbors import KNeighborsClassifier
# Case 1: samples and features are kept at 50%
bagging = BaggingClassifier(KNeighborsClassifier(),
                           max_samples=0.5, max_features=0.5)

# fitting the model
bagging.fit(X_train, y_train)


# Predicting for the entire dataset
Prediction = bagging.predict(X_test)



from sklearn import metrics
# To determine Accuracy
accuracy_bagging = bagging.score(X_test, y_test)
print('Accuracy score for bagging:',accuracy_bagging)

# Precision
precision_bagging = metrics.precision_score(y_test, Prediction, average='weighted')
print('Precision score for bagging:', precision_bagging)
# Recall
recall_bagging = metrics.recall_score(y_test, Prediction, average='weighted')
print('Recall score for bagging:', recall_bagging)
# F1 - Score
F1score_bagging = metrics.f1_score(y_test, Prediction, average='weighted')
print('F1 Score for bagging:', F1score_bagging)



cm_bagging = metrics.confusion_matrix(y_test, Prediction)
print(cm_bagging)
plt.figure(figsize = (9,9))
sns.heatmap(cm_bagging, annot=True, fmt=".4f", linewidths = 0.6, square = True, cmap = 'viridis_r')
plt.ylabel('Actual Outcome')
plt.xlabel('Predicted Outcome')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy_bagging)
plt.title(all_sample_title, size = 15)

from sklearn import metrics
# To determine Accuracy
accuracy_bagging = bagging.score(X_test, y_test)
print('Accuracy score for bagging:',accuracy_bagging)

# Precision
precision_bagging = metrics.precision_score(y_test, Prediction, average='weighted')
print('Precision score for bagging:', precision_bagging)
# Recall
recall_bagging = metrics.recall_score(y_test, Prediction, average='weighted')
print('Recall score for bagging:', recall_bagging)
# F1 - Score
F1score_bagging = metrics.f1_score(y_test, Prediction, average='weighted')
print('F1 Score for bagging:', F1score_bagging)

cm_bagging = metrics.confusion_matrix(y_test, Prediction)
print(cm_bagging)
plt.figure(figsize = (9,9))
sns.heatmap(cm_bagging, annot=True, fmt=".4f", linewidths = 0.6, square = True, cmap = 'viridis_r')
plt.ylabel('Actual Outcome')
plt.xlabel('Predicted Outcome')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy_bagging)
plt.title(all_sample_title, size = 15)

# Case 2: Increased sample size with 50 % features
from sklearn.ensemble import BaggingClassifier
from sklearn.neighbors import KNeighborsClassifier
bagging = BaggingClassifier(KNeighborsClassifier(),
                           max_samples=0.8, max_features=0.5)

# fitting the model
bagging.fit(X_train, y_train)


# Predicting for the entire dataset
Prediction = bagging.predict(X_test)

from sklearn import metrics
# To determine Accuracy
accuracy_bagging_1= bagging.score(X_test, y_test)
print('Accuracy score for bagging_1:',accuracy_bagging_1)

# Precision
precision_bagging_1= metrics.precision_score(y_test, Prediction, average='weighted')
print('Precision score for bagging_1:', precision_bagging_1)
# Recall
recall_bagging_1= metrics.recall_score(y_test, Prediction, average='weighted')
print('Recall score for bagging_1:', recall_bagging_1)
# F1 - Score
F1score_bagging_1= metrics.f1_score(y_test, Prediction, average='weighted')
print('F1 Score for bagging_1:', F1score_bagging_1)

cm_bagging_1 = metrics.confusion_matrix(y_test, Prediction)
print(cm_bagging_1)
plt.figure(figsize = (9,9))
sns.heatmap(cm_bagging_1, annot=True, fmt=".4f", linewidths = 0.6, square = True, cmap = 'viridis_r')
plt.ylabel('Actual Outcome')
plt.xlabel('Predicted Outcome')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy_bagging_1)
plt.title(all_sample_title, size = 15)

# Case 3: Increased max_features with 50% sample size
from sklearn.ensemble import BaggingClassifier
from sklearn.neighbors import KNeighborsClassifier
bagging = BaggingClassifier(KNeighborsClassifier(),
                           max_samples=0.5, max_features=0.8)

# fitting the model
bagging.fit(X_train, y_train)


# Predicting for the entire dataset
Prediction = bagging.predict(X_test)

from sklearn import metrics
# To determine Accuracy
accuracy_bagging_2= bagging.score(X_test, y_test)
print('Accuracy score for bagging_2:',accuracy_bagging_2)

# Precision
precision_bagging_2= metrics.precision_score(y_test, Prediction, average='weighted')
print('Precision score for bagging_2:', precision_bagging_2)
# Recall
recall_bagging_2= metrics.recall_score(y_test, Prediction, average='weighted')
print('Recall score for bagging_2:', recall_bagging_2)
# F1 - Score
F1score_bagging_2= metrics.f1_score(y_test, Prediction, average='weighted')
print('F1 Score for bagging_2:', F1score_bagging_2)

cm_bagging_2 = metrics.confusion_matrix(y_test, Prediction)
print(cm_bagging_2)
plt.figure(figsize = (9,9))
sns.heatmap(cm_bagging_2, annot=True, fmt=".4f", linewidths = 0.6, square = True, cmap = 'viridis_r')
plt.ylabel('Actual Outcome')
plt.xlabel('Predicted Outcome')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy_bagging_2)
plt.title(all_sample_title, size = 15)

# Case 4: Increased max_features and sample size by 80%
from sklearn.ensemble import BaggingClassifier
from sklearn.neighbors import KNeighborsClassifier
bagging = BaggingClassifier(KNeighborsClassifier(),
                           max_samples=0.8, max_features=0.8)

# fitting the model
bagging.fit(X_train, y_train)


# Predicting for the entire dataset
Prediction = bagging.predict(X_test)

from sklearn import metrics
# To determine Accuracy
accuracy_bagging_3= bagging.score(X_test, y_test)
print('Accuracy score for bagging_3:',accuracy_bagging_3)

# Precision
precision_bagging_3= metrics.precision_score(y_test, Prediction, average='weighted')
print('Precision score for bagging_3:', precision_bagging_3)
# Recall
recall_bagging_3= metrics.recall_score(y_test, Prediction, average='weighted')
print('Recall score for bagging_3:', recall_bagging_3)
# F1 - Score
F1score_bagging_3= metrics.f1_score(y_test, Prediction, average='weighted')
print('F1 Score for bagging_3:', F1score_bagging_3)

cm_bagging_3 = metrics.confusion_matrix(y_test, Prediction)
print(cm_bagging_3)
plt.figure(figsize = (9,9))
sns.heatmap(cm_bagging_3, annot=True, fmt=".4f", linewidths = 0.6, square = True, cmap = 'viridis_r')
plt.ylabel('Actual Outcome')
plt.xlabel('Predicted Outcome')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy_bagging_3)
plt.title(all_sample_title, size = 15)

from sklearn.ensemble import BaggingClassifier
from sklearn.naive_bayes import BernoulliNB
bernoulli_nb = BaggingClassifier(BernoulliNB(),
                           max_samples=0.5, max_features=0.5)

# fitting the model
bernoulli_nb.fit(X_train, y_train)


# Predicting for the entire dataset
Prediction = bernoulli_nb.predict(X_test)

from sklearn import metrics

# To determine Accuracy
accuracy_bernoulli_nb = bernoulli_nb.score(X_test, y_test)
print('Accuracy score for bernoulli_nb:',accuracy_bernoulli_nb)

# Precision
precision_bernoulli_nb = metrics.precision_score(y_test, Prediction, average='weighted')
print('Precision score for bernoulli_nb:', precision_bernoulli_nb)
# Recall
recall_bernoulli_nb = metrics.recall_score(y_test, Prediction, average='weighted')
print('Recall score for bernoulli_nb:', recall_bernoulli_nb)
# F1 - Score
F1score_bernoulli_nb = metrics.f1_score(y_test, Prediction, average='weighted')
print('F1 Score for bagging:', F1score_bernoulli_nb)

cm_bernoulli_nb = metrics.confusion_matrix(y_test, Prediction)
print(cm_bernoulli_nb)
plt.figure(figsize = (9,9))
sns.heatmap(cm_bernoulli_nb, annot=True, fmt=".4f", linewidths = 0.6, square = True, cmap = 'viridis_r')
plt.ylabel('Actual Outcome')
plt.xlabel('Predicted Outcome')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy_bernoulli_nb)
plt.title(all_sample_title, size = 15)

# case 2: sample increased with 50% features
from sklearn.ensemble import BaggingClassifier
from sklearn.naive_bayes import BernoulliNB
bernoulli_nb = BaggingClassifier(BernoulliNB(),
                           max_samples=0.8, max_features=0.5)

# fitting the model
bernoulli_nb.fit(X_train, y_train)


# Predicting for the entire dataset
Prediction = bernoulli_nb.predict(X_test)


# To determine Accuracy
accuracy_bernoulli_nb = bernoulli_nb.score(X_test, y_test)
print('Accuracy score for bernoulli_nb:',accuracy_bernoulli_nb)

# Precision
precision_bernoulli_nb = metrics.precision_score(y_test, Prediction, average='weighted')
print('Precision score for bernoulli_nb:', precision_bernoulli_nb)
# Recall
recall_bernoulli_nb = metrics.recall_score(y_test, Prediction, average='weighted')
print('Recall score for bernoulli_nb:', recall_bernoulli_nb)
# F1 - Score
F1score_bernoulli_nb = metrics.f1_score(y_test, Prediction, average='weighted')
print('F1 Score for bagging:', F1score_bernoulli_nb)



cm_bernoulli_nb = metrics.confusion_matrix(y_test, Prediction)
print(cm_bernoulli_nb)
plt.figure(figsize = (9,9))
sns.heatmap(cm_bernoulli_nb, annot=True, fmt=".4f", linewidths = 0.6, square = True, cmap = 'viridis_r')
plt.ylabel('Actual Outcome')
plt.xlabel('Predicted Outcome')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy_bernoulli_nb)
plt.title(all_sample_title, size = 15)

# case 3: 50% sample with 80% features
from sklearn.ensemble import BaggingClassifier
from sklearn.naive_bayes import BernoulliNB
bernoulli_nb = BaggingClassifier(BernoulliNB(),
                           max_samples=0.5, max_features=0.8)

# fitting the model
bernoulli_nb.fit(X_train, y_train)


# Predicting for the entire dataset
Prediction = bernoulli_nb.predict(X_test)


# To determine Accuracy
accuracy_bernoulli_nb = bernoulli_nb.score(X_test, y_test)
print('Accuracy score for bernoulli_nb:',accuracy_bernoulli_nb)

# Precision
precision_bernoulli_nb = metrics.precision_score(y_test, Prediction, average='weighted')
print('Precision score for bernoulli_nb:', precision_bernoulli_nb)
# Recall
recall_bernoulli_nb = metrics.recall_score(y_test, Prediction, average='weighted')
print('Recall score for bernoulli_nb:', recall_bernoulli_nb)
# F1 - Score
F1score_bernoulli_nb = metrics.f1_score(y_test, Prediction, average='weighted')
print('F1 Score for bagging:', F1score_bernoulli_nb)



cm_bernoulli_nb = metrics.confusion_matrix(y_test, Prediction)
print(cm_bernoulli_nb)
plt.figure(figsize = (9,9))
sns.heatmap(cm_bernoulli_nb, annot=True, fmt=".4f", linewidths = 0.6, square = True, cmap = 'viridis_r')
plt.ylabel('Actual Outcome')
plt.xlabel('Predicted Outcome')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy_bernoulli_nb)
plt.title(all_sample_title, size = 15)

# case 4: 80% sample with 80% features
from sklearn.ensemble import BaggingClassifier
from sklearn.naive_bayes import BernoulliNB
bernoulli_nb = BaggingClassifier(BernoulliNB(),
                           max_samples=0.8, max_features=0.8)

# fitting the model
bernoulli_nb.fit(X_train, y_train)


# Predicting for the entire dataset
Prediction = bernoulli_nb.predict(X_test)


# To determine Accuracy
accuracy_bernoulli_nb = bernoulli_nb.score(X_test, y_test)
print('Accuracy score for bernoulli_nb:',accuracy_bernoulli_nb)

# Precision
precision_bernoulli_nb = metrics.precision_score(y_test, Prediction, average='weighted')
print('Precision score for bernoulli_nb:', precision_bernoulli_nb)
# Recall
recall_bernoulli_nb = metrics.recall_score(y_test, Prediction, average='weighted')
print('Recall score for bernoulli_nb:', recall_bernoulli_nb)
# F1 - Score
F1score_bernoulli_nb = metrics.f1_score(y_test, Prediction, average='weighted')
print('F1 Score for bagging:', F1score_bernoulli_nb)



cm_bernoulli_nb = metrics.confusion_matrix(y_test, Prediction)
print(cm_bernoulli_nb)
plt.figure(figsize = (9,9))
sns.heatmap(cm_bernoulli_nb, annot=True, fmt=".4f", linewidths = 0.6, square = True, cmap = 'viridis_r')
plt.ylabel('Actual Outcome')
plt.xlabel('Predicted Outcome')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy_bernoulli_nb)
plt.title(all_sample_title, size = 15)

# case 1: 50% samples with 50% features
from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
decision_tree = BaggingClassifier(DecisionTreeClassifier(max_depth=6, random_state=42),
                           max_samples=0.5, max_features=0.5, random_state=42)

# fitting the model
decision_tree.fit(X_train, y_train)


# Predicting for the entire dataset
Prediction = decision_tree.predict(X_test)


# To determine Accuracy
accuracy_decision_tree = decision_tree.score(X_test, y_test)
print('Accuracy score for decision_tree:',accuracy_decision_tree)

# Precision
precision_decision_tree = metrics.precision_score(y_test, Prediction, average='weighted')
print('Precision score for decision_tree:', precision_decision_tree)
# Recall
recall_decision_tree = metrics.recall_score(y_test, Prediction, average='weighted')
print('Recall score for decision_tree:', recall_decision_tree)
# F1 - Score
F1score_decision_tree = metrics.f1_score(y_test, Prediction, average='weighted')
print('F1 Score for bagging:', F1score_decision_tree)



cm_decision_tree= metrics.confusion_matrix(y_test, Prediction)
print(cm_decision_tree)
plt.figure(figsize = (9,9))
sns.heatmap(cm_decision_tree, annot=True, fmt=".4f", linewidths = 0.6, square = True, cmap = 'viridis_r')
plt.ylabel('Actual Outcome')
plt.xlabel('Predicted Outcome')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy_decision_tree)
plt.title(all_sample_title, size = 15)

# case 2: 50% samples with 80% features
from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
decision_tree = BaggingClassifier(DecisionTreeClassifier(max_depth=6, random_state=42),
                           max_samples=0.5, max_features=0.8, random_state=42)

# fitting the model
decision_tree.fit(X_train, y_train)


# Predicting for the entire dataset
Prediction = decision_tree.predict(X_test)


# To determine Accuracy
accuracy_decision_tree = decision_tree.score(X_test, y_test)
print('Accuracy score for decision_tree:',accuracy_decision_tree)

# Precision
precision_decision_tree = metrics.precision_score(y_test, Prediction, average='weighted')
print('Precision score for decision_tree:', precision_decision_tree)
# Recall
recall_decision_tree = metrics.recall_score(y_test, Prediction, average='weighted')
print('Recall score for decision_tree:', recall_decision_tree)
# F1 - Score
F1score_decision_tree = metrics.f1_score(y_test, Prediction, average='weighted')
print('F1 Score for bagging:', F1score_decision_tree)



cm_decision_tree= metrics.confusion_matrix(y_test, Prediction)
print(cm_decision_tree)
plt.figure(figsize = (9,9))
sns.heatmap(cm_decision_tree, annot=True, fmt=".4f", linewidths = 0.6, square = True, cmap = 'viridis_r')
plt.ylabel('Actual Outcome')
plt.xlabel('Predicted Outcome')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy_decision_tree)
plt.title(all_sample_title, size = 15)

# case 3: 80% samples with 50% features
from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
decision_tree = BaggingClassifier(DecisionTreeClassifier(max_depth=6, random_state=42),
                           max_samples=0.8, max_features=0.5, random_state=42)

# fitting the model
decision_tree.fit(X_train, y_train)


# Predicting for the entire dataset
Prediction = decision_tree.predict(X_test)


# To determine Accuracy
accuracy_decision_tree = decision_tree.score(X_test, y_test)
print('Accuracy score for decision_tree:',accuracy_decision_tree)

# Precision
precision_decision_tree = metrics.precision_score(y_test, Prediction, average='weighted')
print('Precision score for decision_tree:', precision_decision_tree)
# Recall
recall_decision_tree = metrics.recall_score(y_test, Prediction, average='weighted')
print('Recall score for decision_tree:', recall_decision_tree)
# F1 - Score
F1score_decision_tree = metrics.f1_score(y_test, Prediction, average='weighted')
print('F1 Score for bagging:', F1score_decision_tree)



cm_decision_tree= metrics.confusion_matrix(y_test, Prediction)
print(cm_decision_tree)
plt.figure(figsize = (9,9))
sns.heatmap(cm_decision_tree, annot=True, fmt=".4f", linewidths = 0.6, square = True, cmap = 'viridis_r')
plt.ylabel('Actual Outcome')
plt.xlabel('Predicted Outcome')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy_decision_tree)
plt.title(all_sample_title, size = 15)

# case 4: 80% samples with 80% features
from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
decision_tree = BaggingClassifier(DecisionTreeClassifier(max_depth=6, random_state=42),
                           max_samples=0.8, max_features=0.8, random_state=42)

# fitting the model
decision_tree.fit(X_train, y_train)


# Predicting for the entire dataset
Prediction = decision_tree.predict(X_test)


# To determine Accuracy
accuracy_decision_tree = decision_tree.score(X_test, y_test)
print('Accuracy score for decision_tree:',accuracy_decision_tree)

# Precision
precision_decision_tree = metrics.precision_score(y_test, Prediction, average='weighted')
print('Precision score for decision_tree:', precision_decision_tree)
# Recall
recall_decision_tree = metrics.recall_score(y_test, Prediction, average='weighted')
print('Recall score for decision_tree:', recall_decision_tree)
# F1 - Score
F1score_decision_tree = metrics.f1_score(y_test, Prediction, average='weighted')
print('F1 Score for bagging:', F1score_decision_tree)



cm_decision_tree= metrics.confusion_matrix(y_test, Prediction)
print(cm_decision_tree)
plt.figure(figsize = (9,9))
sns.heatmap(cm_decision_tree, annot=True, fmt=".4f", linewidths = 0.6, square = True, cmap = 'viridis_r')
plt.ylabel('Actual Outcome')
plt.xlabel('Predicted Outcome')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy_decision_tree)
plt.title(all_sample_title, size = 15)

# case 1: 50% samples with 50% features
from sklearn.ensemble import BaggingClassifier
from sklearn.svm import LinearSVC
linear_svc = BaggingClassifier(LinearSVC(random_state=42, max_iter=6000),
                           max_samples=0.8, max_features=0.5, random_state=42)

# fitting the model
linear_svc.fit(X_train, y_train)


# Predicting for the entire dataset
Prediction = linear_svc.predict(X_test)


# To determine Accuracy
accuracy_linear_svc = linear_svc.score(X_test, y_test)
print('Accuracy score for linear_svc:',accuracy_linear_svc)

# Precision
precision_linear_svc = metrics.precision_score(y_test, Prediction, average='weighted')
print('Precision score for linear_svc:', precision_linear_svc)
# Recall
recall_linear_svc = metrics.recall_score(y_test, Prediction, average='weighted')
print('Recall score for linear_svc:', recall_linear_svc)
# F1 - Score
F1score_linear_svc = metrics.f1_score(y_test, Prediction, average='weighted')
print('F1 Score for linear_svc:', F1score_linear_svc)



cm_linear_svc= metrics.confusion_matrix(y_test, Prediction)
print(cm_linear_svc)
plt.figure(figsize = (9,9))
sns.heatmap(cm_linear_svc, annot=True, fmt=".4f", linewidths = 0.6, square = True, cmap = 'viridis_r')
plt.ylabel('Actual Outcome')
plt.xlabel('Predicted Outcome')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy_linear_svc)
plt.title(all_sample_title, size = 15)

# case 1: sample 50% features 50%
from sklearn.ensemble import BaggingClassifier
from sklearn.neural_network import BernoulliRBM
bernoulli_RBM = BaggingClassifier(BernoulliRBM(random_state=42),
                           max_samples=0.5, max_features=0.5)

# fitting the model
bernoulli_RBM.fit(X_train, y_train)
# Predicting for the entire dataset
Prediction = bernoulli_RBM.predict(X_test)


# To determine Accuracy
accuracy_bernoulli_RBM = bernoulli_nb.score(X_test, y_test)
print('Accuracy score for bernoulli_RBM :',accuracy_bernoulli_RBM )

# Precision
precision_bernoulli_RBM  = metrics.precision_score(y_test, Prediction, average='weighted')
print('Precision score for bernoulli_RBM :', precision_bernoulli_RBM )
# Recall
recall_bernoulli_RBM  = metrics.recall_score(y_test, Prediction, average='weighted')
print('Recall score for bernoulli_RBM :', recall_bernoulli_RBM )
# F1 - Score
F1score_bernoulli_RBM  = metrics.f1_score(y_test, Prediction, average='weighted')
print('F1 Score for bagging:', F1score_bernoulli_RBM)



cm_bernoulli_RBM = metrics.confusion_matrix(y_test, Prediction)
print(cm_bernoulli_RBM )
plt.figure(figsize = (9,9))
sns.heatmap(cm_bernoulli_RBM, annot=True, fmt=".4f", linewidths = 0.6, square = True, cmap = 'viridis_r')
plt.ylabel('Actual Outcome')
plt.xlabel('Predicted Outcome')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy_bernoulli_RBM)
plt.title(all_sample_title, size = 15)

# case 1: sample 50% features 50%
from sklearn.ensemble import BaggingClassifier
from sklearn.neural_network import MLPClassifier
MLP_classifier = BaggingClassifier(MLPClassifier(random_state=42),
                           max_samples=0.5, max_features=0.5)

# fitting the model
MLP_classifier.fit(X_train, y_train)
# Predicting for the entire dataset
Prediction = MLP_classifier.predict(X_test)


# To determine Accuracy
accuracy_MLP_classifier = MLP_classifier.score(X_test, y_test)
print('Accuracy score for MLP_classifier :',accuracy_MLP_classifier )

# Precision
precision_MLP_classifier  = metrics.precision_score(y_test, Prediction, average='weighted')
print('Precision score for MLP_classifier :', precision_MLP_classifier )
# Recall
recall_MLP_classifier  = metrics.recall_score(y_test, Prediction, average='weighted')
print('Recall score for MLP_classifier :', recall_MLP_classifier)
# F1 - Score
F1score_MLP_classifier  = metrics.f1_score(y_test, Prediction, average='weighted')
print('F1 Score for MLP_classifier:', F1score_MLP_classifier)



cm_MLP_classifier = metrics.confusion_matrix(y_test, Prediction)
print(cm_MLP_classifier)
plt.figure(figsize = (9,9))
sns.heatmap(cm_MLP_classifier, annot=True, fmt=".4f", linewidths = 0.6, square = True, cmap = 'viridis_r')
plt.ylabel('Actual Outcome')
plt.xlabel('Predicted Outcome')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy_MLP_classifier)
plt.title(all_sample_title, size = 15)



# Case 1: max_features and sample size = 50%
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
bagging = RandomForestClassifier(n_estimators=96, random_state=42,
                           max_samples=0.5, max_features=0.5)

# fitting the model
bagging.fit(X_train, y_train)


# Predicting for the entire dataset
Prediction = bagging.predict(X_test)

# Model Performance Evaluation

# Cross-Validation Score 
scores = cross_val_score(bagging, X_train, y_train, scoring='accuracy', cv=5)
print('Cross validation score', scores)
from sklearn import metrics
# To determine Accuracy
accuracy_bagging = bagging.score(X_test, y_test)
print('Accuracy score for bagging:',accuracy_bagging)

# Precision
precision_bagging = metrics.precision_score(y_test, Prediction, average='weighted')
print('Precision score for bagging:', precision_bagging)
# Recall
recall_bagging = metrics.recall_score(y_test, Prediction, average='weighted')
print('Recall score for bagging:', recall_bagging)
# F1 - Score
F1score_bagging = metrics.f1_score(y_test, Prediction, average='weighted')
print('F1 Score for bagging:', F1score_bagging)



cm_bagging = metrics.confusion_matrix(y_test, Prediction)
print(cm_bagging)
plt.figure(figsize = (9,9))
sns.heatmap(cm_bagging, annot=True, fmt=".4f", linewidths = 0.6, square = True, cmap = 'viridis_r')
plt.ylabel('Actual Outcome')
plt.xlabel('Predicted Outcome')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy_bagging)
plt.title(all_sample_title, size = 15)

#plot graph of feature importances for better visualization
feat_importances = pd.Series(bagging.feature_importances_, index=X.columns)
feat_importances.nlargest(18).plot(kind='barh')
plt.show()

# Case 2: max_features = 50% and sample size = 80%
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
bagging = RandomForestClassifier(n_estimators=96, random_state=42,
                           max_samples=0.8, max_features=0.5)

# fitting the model
bagging.fit(X_train, y_train)


# Predicting for the entire dataset
Prediction = bagging.predict(X_test)


from sklearn import metrics
# To determine Accuracy
accuracy_bagging = bagging.score(X_test, y_test)
print('Accuracy score for bagging:',accuracy_bagging)

# Precision
precision_bagging = metrics.precision_score(y_test, Prediction, average='weighted')
print('Precision score for bagging:', precision_bagging)
# Recall
recall_bagging = metrics.recall_score(y_test, Prediction, average='weighted')
print('Recall score for bagging:', recall_bagging)
# F1 - Score
F1score_bagging = metrics.f1_score(y_test, Prediction, average='weighted')
print('F1 Score for bagging:', F1score_bagging)



cm_bagging = metrics.confusion_matrix(y_test, Prediction)
print(cm_bagging)
plt.figure(figsize = (9,9))
sns.heatmap(cm_bagging, annot=True, fmt=".4f", linewidths = 0.6, square = True, cmap = 'viridis_r')
plt.ylabel('Actual Outcome')
plt.xlabel('Predicted Outcome')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy_bagging)
plt.title(all_sample_title, size = 15)

# Case 3: max_features= 80% and sample size = 80%
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
bagging = RandomForestClassifier(n_estimators=96, random_state=42,
                           max_samples=0.80, max_features=0.80)

# fitting the model
bagging.fit(X_train, y_train)


# Predicting for the entire dataset
Prediction = bagging.predict(X_test)


from sklearn import metrics
# To determine Accuracy
accuracy_bagging = bagging.score(X_test, y_test)
print('Accuracy score for bagging:',accuracy_bagging)

# Precision
precision_bagging = metrics.precision_score(y_test, Prediction, average='weighted')
print('Precision score for bagging:', precision_bagging)
# Recall
recall_bagging = metrics.recall_score(y_test, Prediction, average='weighted')
print('Recall score for bagging:', recall_bagging)
# F1 - Score
F1score_bagging = metrics.f1_score(y_test, Prediction, average='weighted')
print('F1 Score for bagging:', F1score_bagging)



cm_bagging = metrics.confusion_matrix(y_test, Prediction)
print(cm_bagging)
plt.figure(figsize = (9,9))
sns.heatmap(cm_bagging, annot=True, fmt=".4f", linewidths = 0.6, square = True, cmap = 'viridis_r')
plt.ylabel('Actual Outcome')
plt.xlabel('Predicted Outcome')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy_bagging)
plt.title(all_sample_title, size = 15)

# Case 3: max_features and sample size 
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
bagging = RandomForestClassifier(n_estimators=96, random_state=42,
                           max_samples=1.0, max_features=1.0)

# fitting the model
bagging.fit(X_train, y_train)


# Predicting for the entire dataset
Prediction = bagging.predict(X_test)


from sklearn import metrics
# To determine Accuracy
accuracy_bagging = bagging.score(X_test, y_test)
print('Accuracy score for bagging:',accuracy_bagging)

# Precision
precision_bagging = metrics.precision_score(y_test, Prediction, average='weighted')
print('Precision score for bagging:', precision_bagging)
# Recall
recall_bagging = metrics.recall_score(y_test, Prediction, average='weighted')
print('Recall score for bagging:', recall_bagging)
# F1 - Score
F1score_bagging = metrics.f1_score(y_test, Prediction, average='weighted')
print('F1 Score for bagging:', F1score_bagging)



cm_bagging = metrics.confusion_matrix(y_test, Prediction)
print(cm_bagging)
plt.figure(figsize = (9,9))
sns.heatmap(cm_bagging, annot=True, fmt=".4f", linewidths = 0.6, square = True, cmap = 'viridis_r')
plt.ylabel('Actual Outcome')
plt.xlabel('Predicted Outcome')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy_bagging)
plt.title(all_sample_title, size = 15)

#print(bagging.feature_importances_) #use inbuilt class feature_importances of tree based classifiers
#plot graph of feature importances for better visualization
feat_importances = pd.Series(bagging.feature_importances_, index=X.columns)
feat_importances.nlargest(18).plot(kind='barh')
plt.show()

# Case 1: Gradient Boosting
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
Gboost_classifier = GradientBoostingClassifier(n_estimators=96, learning_rate=1.0, max_depth=1, random_state=42).fit(X_train, y_train)

# fitting the model
#adaboost_classifier.fit(X_train, y_train)


# Predicting for the entire dataset
Prediction = Gboost_classifier.predict(X_test)


from sklearn import metrics
# To determine Accuracy
accuracy_Gboost_classifier = Gboost_classifier.score(X_test, y_test)
print('Accuracy score for Gboost_classifier:',accuracy_Gboost_classifier)

# Precision
precision_Gboost_classifier= metrics.precision_score(y_test, Prediction, average='weighted')
print('Precision score for Gboost_classifier:', precision_Gboost_classifier)
# Recall
recall_Gboost_classifier = metrics.recall_score(y_test, Prediction, average='weighted')
print('Recall score for Gboost_classifier:', recall_Gboost_classifier)
# F1 - Score
F1score_Gboost_classifier = metrics.f1_score(y_test, Prediction, average='weighted')
print('F1 Score for Gboost_classifier:', F1score_Gboost_classifier)



cm_Gboost_classifier= metrics.confusion_matrix(y_test, Prediction)
print(cm_Gboost_classifier)
plt.figure(figsize = (9,9))
sns.heatmap(cm_Gboost_classifier, annot=True, fmt=".4f", linewidths = 0.6, square = True, cmap = 'viridis_r')
plt.ylabel('Actual Outcome')
plt.xlabel('Predicted Outcome')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy_Gboost_classifier)
plt.title(all_sample_title, size = 15)

#plot graph of feature importances for better visualization
feat_importances = pd.Series(Gboost_classifier.feature_importances_, index=X.columns)
feat_importances.nlargest(18).plot(kind='barh')
plt.show()

# Case 2: HistGradientBoosting Classifier
from sklearn.ensemble import HistGradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
Gboost_classifier = HistGradientBoostingClassifier( max_iter= 96, random_state=42).fit(X_train, y_train)

# fitting the model
#adaboost_classifier.fit(X_train, y_train)


# Predicting for the entire dataset
Prediction = Gboost_classifier.predict(X_test)


from sklearn import metrics
# To determine Accuracy
accuracy_Gboost_classifier = Gboost_classifier.score(X_test, y_test)
print('Accuracy score for Gboost_classifier:',accuracy_Gboost_classifier)

# Precision
precision_Gboost_classifier= metrics.precision_score(y_test, Prediction, average='weighted')
print('Precision score for Gboost_classifier:', precision_Gboost_classifier)
# Recall
recall_Gboost_classifier = metrics.recall_score(y_test, Prediction, average='weighted')
print('Recall score for Gboost_classifier:', recall_Gboost_classifier)
# F1 - Score
F1score_Gboost_classifier = metrics.f1_score(y_test, Prediction, average='weighted')
print('F1 Score for Gboost_classifier:', F1score_Gboost_classifier)



cm_Gboost_classifier= metrics.confusion_matrix(y_test, Prediction)
print(cm_Gboost_classifier)
plt.figure(figsize = (9,9))
sns.heatmap(cm_Gboost_classifier, annot=True, fmt=".4f", linewidths = 0.6, square = True, cmap = 'viridis_r')
plt.ylabel('Actual Outcome')
plt.xlabel('Predicted Outcome')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy_Gboost_classifier)
plt.title(all_sample_title, size = 15)

#plot graph of feature importances for better visualization
feat_importances = pd.Series(Gboost_classifier.feature_importances_, index=X.columns)
feat_importances.nlargest(18).plot(kind='barh')
plt.show()

# Case 2: HistGradientBoosting Classifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.neighbors import KNeighborsClassifier
Gboost_classifier = AdaBoostClassifier( n_estimators=96, random_state=42).fit(X_train, y_train)

# fitting the model
#adaboost_classifier.fit(X_train, y_train)


# Predicting for the entire dataset
Prediction = Gboost_classifier.predict(X_test)


from sklearn import metrics
# To determine Accuracy
accuracy_Gboost_classifier = Gboost_classifier.score(X_test, y_test)
print('Accuracy score for Gboost_classifier:',accuracy_Gboost_classifier)

# Precision
precision_Gboost_classifier= metrics.precision_score(y_test, Prediction, average='weighted')
print('Precision score for Gboost_classifier:', precision_Gboost_classifier)
# Recall
recall_Gboost_classifier = metrics.recall_score(y_test, Prediction, average='weighted')
print('Recall score for Gboost_classifier:', recall_Gboost_classifier)
# F1 - Score
F1score_Gboost_classifier = metrics.f1_score(y_test, Prediction, average='weighted')
print('F1 Score for Gboost_classifier:', F1score_Gboost_classifier)



cm_Gboost_classifier= metrics.confusion_matrix(y_test, Prediction)
print(cm_Gboost_classifier)
plt.figure(figsize = (9,9))
sns.heatmap(cm_Gboost_classifier, annot=True, fmt=".4f", linewidths = 0.6, square = True, cmap = 'viridis_r')
plt.ylabel('Actual Outcome')
plt.xlabel('Predicted Outcome')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy_Gboost_classifier)
plt.title(all_sample_title, size = 15)

#plot graph of feature importances for better visualization
feat_importances = pd.Series(Gboost_classifier.feature_importances_, index=X.columns)
feat_importances.nlargest(18).plot(kind='barh')
plt.show()

# Case 3: ExtraTrees Classifier
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.neighbors import KNeighborsClassifier
Gboost_classifier = ExtraTreesClassifier(n_estimators=100, random_state=42).fit(X_train, y_train)

# fitting the model
#adaboost_classifier.fit(X_train, y_train)


# Predicting for the entire dataset
Prediction = Gboost_classifier.predict(X_test)


from sklearn import metrics
# To determine Accuracy
accuracy_Gboost_classifier = Gboost_classifier.score(X_test, y_test)
print('Accuracy score for Gboost_classifier:',accuracy_Gboost_classifier)

# Precision
precision_Gboost_classifier= metrics.precision_score(y_test, Prediction, average='weighted')
print('Precision score for Gboost_classifier:', precision_Gboost_classifier)
# Recall
recall_Gboost_classifier = metrics.recall_score(y_test, Prediction, average='weighted')
print('Recall score for Gboost_classifier:', recall_Gboost_classifier)
# F1 - Score
F1score_Gboost_classifier = metrics.f1_score(y_test, Prediction, average='weighted')
print('F1 Score for Gboost_classifier:', F1score_Gboost_classifier)



cm_Gboost_classifier= metrics.confusion_matrix(y_test, Prediction)
print(cm_Gboost_classifier)
plt.figure(figsize = (9,9))
sns.heatmap(cm_Gboost_classifier, annot=True, fmt=".4f", linewidths = 0.6, square = True, cmap = 'viridis_r')
plt.ylabel('Actual Outcome')
plt.xlabel('Predicted Outcome')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy_Gboost_classifier)
plt.title(all_sample_title, size = 15)

#plot graph of feature importances for better visualization
feat_importances = pd.Series(Gboost_classifier.feature_importances_, index=X.columns)
feat_importances.nlargest(18).plot(kind='barh')
plt.show()

# Case 4: StackingClassifier Classifier
from sklearn.ensemble import StackingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import RidgeClassifierCV, PassiveAggressiveClassifier
#from sklearn.neighbors import KNeighborsRegressor
estimators = [('ridge',  RidgeClassifierCV()), ('PassiveAggressive', PassiveAggressiveClassifier(random_state=42)),('knn', KNeighborsClassifier(n_neighbors=20,metric='euclidean'))]
final_estimator = GradientBoostingClassifier(n_estimators=25, subsample=0.5, min_samples_leaf=25, max_features=1, random_state=42)

Gboost_classifier = StackingClassifier(estimators=estimators, final_estimator=final_estimator).fit(X_train, y_train)

# fitting the model
#adaboost_classifier.fit(X_train, y_train)


# Predicting for the entire dataset
Prediction = Gboost_classifier.predict(X_test)


from sklearn import metrics
# To determine Accuracy
accuracy_Gboost_classifier = Gboost_classifier.score(X_test, y_test)
print('Accuracy score for Gboost_classifier:',accuracy_Gboost_classifier)

# Precision
precision_Gboost_classifier= metrics.precision_score(y_test, Prediction, average='weighted')
print('Precision score for Gboost_classifier:', precision_Gboost_classifier)
# Recall
recall_Gboost_classifier = metrics.recall_score(y_test, Prediction, average='weighted')
print('Recall score for Gboost_classifier:', recall_Gboost_classifier)
# F1 - Score
F1score_Gboost_classifier = metrics.f1_score(y_test, Prediction, average='weighted')
print('F1 Score for Gboost_classifier:', F1score_Gboost_classifier)



cm_Gboost_classifier= metrics.confusion_matrix(y_test, Prediction)
print(cm_Gboost_classifier)
plt.figure(figsize = (9,9))
sns.heatmap(cm_Gboost_classifier, annot=True, fmt=".4f", linewidths = 0.6, square = True, cmap = 'viridis_r')
plt.ylabel('Actual Outcome')
plt.xlabel('Predicted Outcome')
all_sample_title = 'Accuracy Score: {0}'.format(accuracy_Gboost_classifier)
plt.title(all_sample_title, size = 15)

#plot graph of feature importances for better visualization
feat_importances = pd.Series(Gboost_classifier.feature_importances_, index=X.columns)
feat_importances.nlargest(18).plot(kind='barh')
plt.show()

# Case 5 : Voting Classifier 
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import VotingClassifier


clf1 = LogisticRegression(random_state=1)
clf2 = RandomForestClassifier(n_estimators=50, random_state=42)
clf3 = GaussianNB()


eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],voting='hard')

for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):
       scores = cross_val_score(clf, X, y, scoring='accuracy', cv=5)
       print("Accuracy: %0.2f (+/- %0.2f) [%s]" % (scores.mean(), scores.std(), label))

"""**Case 1: Sample Size = 50%,  Features = 50% **

Accuracy score for bagging: 0.852

Precision score for bagging: 0.8006255012028869

Recall score for bagging: 0.852

F1 Score for bagging: 0.7861869616432307



**Case 2: Sample Size = 80%,  Features = 50% **

Accuracy score for bagging_1: 0.8524

Precision score for bagging_1: 0.8141905646968787

Recall score for bagging_1: 0.8524

F1 Score for bagging_1: 0.7865787841316993




**Case 3: Sample Size = 50%,  Features = 80% **


Accuracy score for bagging_2: 0.8522

Precision score for bagging_2: 0.805184174138008

Recall score for bagging_2: 0.8522

F1 Score for bagging_2: 0.7875829501547085



**Case 4: Sample Size = 80%,  Features = 80% **


Accuracy score for bagging_3: 0.8511

Precision score for bagging_3: 0.7916006256846242

Recall score for bagging_3: 0.8511

F1 Score for bagging_3: 0.7887996576567924
"""

from sklearn.tree import DecisionTreeClassifier 
from sklearn import tree

# Fitting the model 

decision_tree= DecisionTreeClassifier(max_depth = 6).fit(X_train, y_train)

# Plotting the tree after fitting
tree.plot_tree(decision_tree)  # works


# Predicting for the entire dataset
Prediction = decision_tree.predict(X_test)

Prediction

# To determine Accuracy
accuracy_decision_tree = decision_tree.score(X_test, y_test)
print('Accuracy score for decision tree:', accuracy_decision_tree)

# Precision
precision_decision_tree = metrics.precision_score(y_test, Prediction, average='weighted')
print('Precision score for decision tree:', precision_decision_tree)
# Recall
recall_decision_tree = metrics.recall_score(y_test, Prediction, average='weighted')
print('Recall score for decision tree:', recall_decision_tree)
# F1 - Score
F1score_decision_tree = metrics.f1_score(y_test, Prediction, average='weighted')
print('F1 Score for decision tree:', F1score_decision_tree)

! pip install lazypredict
from lazypredict.Supervised import LazyClassifier

clf=LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None, predictions=True)
models,predictions = clf.fit(X_train, X_test, y_train, y_test)

print(models)

print(predictions)

from lazypredict.Supervised import ClassifierMixin,